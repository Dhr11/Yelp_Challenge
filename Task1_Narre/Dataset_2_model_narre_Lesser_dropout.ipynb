{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Dataset 2 model narre Lesser dropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG6OZzVADBKM",
        "colab_type": "code",
        "outputId": "34e7d50f-cdbf-4ecb-e8ca-295627f735de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#from tensorflow.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.layers import Embedding, Concatenate, Add, Activation,Dot\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten,Reshape, MaxPooling2D,MaxPooling3D\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling1D, Embedding, Dropout, AdditiveAttention, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeVNx2H3ETsD",
        "colab_type": "code",
        "outputId": "de6958da-74c7-4b5a-fc1b-bda21a733f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP03F9raD386",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/narre_data/NARRE_para_filtered_short_review.pkl','rb') as f:\n",
        "  para = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/narre_data/yelp_NARRE_train_filtered_short_review.pkl','rb') as f:\n",
        "  train_data = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/narre_data/yelp_NARRE_valid_filtered_short_review.pkl','rb') as f:\n",
        "  valid_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_kDvui8GQK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loading the paramters specific to the data created\n",
        "## parameters like total number of users, business\n",
        "## Max sequence length for user and business reviews\n",
        "## Number of reviews per user and business\n",
        "## text for user and business\n",
        "## Word dictionary for user text and business text\n",
        "\n",
        "total_items = para['item_num']\n",
        "total_users = para['user_num']\n",
        "USER_SEQUENCE_LENGTH = para['review_len_u']\n",
        "ITEM_SEQUENCE_LENGTH = para['review_len_i']\n",
        "user_review_num = para['review_num_u']\n",
        "item_review_num = para['review_num_i']\n",
        "u_text = para['u_text']\n",
        "i_text = para['i_text']\n",
        "user_word_index = para['user_vocab']\n",
        "item_word_index = para['item_vocab']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aACFlZ9qxaf0",
        "colab_type": "code",
        "outputId": "f669170a-af39-4ef5-add3-cffce62164f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(total_items,total_users,USER_SEQUENCE_LENGTH,ITEM_SEQUENCE_LENGTH,user_review_num,item_review_num)#,u_text,i_text,user_word_index,item_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3940 6113 114 114 85 169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQnFSHGIDBKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Rest of parameters for the model\n",
        "## drop rate of 0.4\n",
        "## Two filter sizes for text cnn, and each has 100 filters\n",
        "## Attention dimension kept as 32, same as latent embedding dimension\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "\n",
        "filter_sizes = [3,4]\n",
        "\n",
        "conv_filters = 100\n",
        "drop_rate = 0.2\n",
        "attention_units = 32\n",
        "embedding_id = 32\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qyPlrNODBKZ",
        "colab_type": "code",
        "outputId": "c9eeb9a3-950c-4ef0-f725-e93cf3e64021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Loading the glove pre trained embedding and making a matrix named embedding index for it\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/yelp_dataset/Dataset/glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors in Glove 6B 100d.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9wh_9VPDBKf",
        "colab_type": "code",
        "outputId": "a987a878-3d55-415d-c9cd-f442ec4e6b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "## here we make and fill the embedding matrix for user text, by retreiving vectors from embedding index cretaed before\n",
        "\n",
        "user_embedding_matrix = np.random.random((len(user_word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in user_word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        user_embedding_matrix[i] = embedding_vector\n",
        "user_embedding_layer = Embedding(len(user_word_index) + 1,\n",
        "                            EMBEDDING_DIM,weights=[user_embedding_matrix],\n",
        "                            input_length=USER_SEQUENCE_LENGTH,trainable=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1UF2IhDBKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## here we make and fill the embedding matrix for business text, by retreiving vectors from embedding index created before\n",
        "\n",
        "item_embedding_matrix = np.random.random((len(item_word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in item_word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        item_embedding_matrix[i] = embedding_vector\n",
        "item_embedding_layer = Embedding(len(item_word_index) + 1,\n",
        "                            EMBEDDING_DIM,weights=[item_embedding_matrix],\n",
        "                            input_length=ITEM_SEQUENCE_LENGTH,trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXs6QL3fDBKk",
        "colab_type": "code",
        "outputId": "4906faa2-eb83-45f5-a70f-ab4e8f5b6ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "## Passing the user text to embedding and convolution layers\n",
        "\n",
        "user_sequence_input = Input(shape=(USER_SEQUENCE_LENGTH,user_review_num), dtype='int32')\n",
        "print(user_sequence_input.shape)\n",
        "user_embedded_reviews = user_embedding_layer(user_sequence_input)\n",
        "print(user_embedded_reviews.shape)\n",
        "user_embedded_reviews_flat = Reshape((user_review_num,USER_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(user_embedded_reviews)\n",
        "print(user_embedded_reviews_flat.shape)\n",
        "conv_out = []\n",
        "for f_size in filter_sizes:\n",
        "    l_cov1= Conv3D(conv_filters, (1,f_size,EMBEDDING_DIM), activation='relu',padding='valid')(user_embedded_reviews_flat)\n",
        "    print(l_cov1.shape)\n",
        "    l_pool1 = MaxPooling3D(pool_size =(1,USER_SEQUENCE_LENGTH-f_size+1,1),padding='valid')(l_cov1)\n",
        "    print(l_pool1.shape)\n",
        "    l_flat = Flatten()(l_pool1)\n",
        "    print(l_flat.shape)\n",
        "    conv_out.append(l_flat)\n",
        "conv_joined = Concatenate()(conv_out)\n",
        "print(conv_joined.shape)    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 114, 85)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(?, 114, 85, 100)\n",
            "(?, 85, 114, 100, 1)\n",
            "(?, 85, 112, 1, 100)\n",
            "(?, 85, 1, 1, 100)\n",
            "(?, 8500)\n",
            "(?, 85, 111, 1, 100)\n",
            "(?, 85, 1, 1, 100)\n",
            "(?, 8500)\n",
            "(?, 17000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq8c2BfRDBKm",
        "colab_type": "code",
        "outputId": "113cebc9-1647-480c-9752-2f9ef6ca0505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "## Passing the business text to embedding and convolution layers\n",
        "\n",
        "item_sequence_input = Input(shape=(ITEM_SEQUENCE_LENGTH,item_review_num), dtype='int32')\n",
        "item_embedded_reviews = item_embedding_layer(item_sequence_input)\n",
        "item_embedded_reviews_flat = Reshape((item_review_num,ITEM_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(item_embedded_reviews)\n",
        "print(item_embedded_reviews_flat.shape)\n",
        "item_conv_out = []\n",
        "for f_size in filter_sizes:\n",
        "    l_cov1= Conv3D(conv_filters, (1,f_size,EMBEDDING_DIM), activation='relu',padding='valid')(item_embedded_reviews_flat)\n",
        "    print(l_cov1.shape)\n",
        "    l_pool1 = MaxPooling3D(pool_size =(1,ITEM_SEQUENCE_LENGTH-f_size+1,1),padding='valid')(l_cov1)\n",
        "    print(l_pool1.shape)\n",
        "    l_flat = Flatten()(l_pool1)\n",
        "    print(l_flat.shape)\n",
        "    item_conv_out.append(l_flat)\n",
        "item_conv_joined = Concatenate()(item_conv_out)\n",
        "print(item_conv_joined.shape)    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 169, 114, 100, 1)\n",
            "(?, 169, 112, 1, 100)\n",
            "(?, 169, 1, 1, 100)\n",
            "(?, 16900)\n",
            "(?, 169, 111, 1, 100)\n",
            "(?, 169, 1, 1, 100)\n",
            "(?, 16900)\n",
            "(?, 33800)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aaPm31IDBKo",
        "colab_type": "code",
        "outputId": "8122e9bf-099e-4113-c917-e981eb642d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "## concatenate convolution fetures for user\n",
        "\n",
        "user_flat = Reshape((user_review_num,conv_filters*len(filter_sizes)))(conv_joined)\n",
        "print(user_flat.shape)\n",
        "user_flat = Dropout(drop_rate)(user_flat)\n",
        "\n",
        "#total_item = 1000000\n",
        "u_iid = Input(shape=(user_review_num), dtype='int32')\n",
        "print(u_iid.shape)\n",
        "init_a = keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=123)\n",
        "init_b = tf.keras.initializers.Constant(0.1)\n",
        "\n",
        "## retreiving the business ids embeddings for a specific user\n",
        "\n",
        "item_id_embedding = Embedding(total_items + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a,embeddings_regularizer=l2(0.001))\n",
        "item_embs = item_id_embedding(u_iid)\n",
        "item_embs = Activation('relu')(item_embs)\n",
        "print(item_embs.shape)\n",
        "##\n",
        "## Applying user level attention\n",
        "\n",
        "\n",
        "user_atten = Dense(attention_units,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001), kernel_initializer=init_a, bias_initializer=init_b)(user_flat)\n",
        "print(user_atten.shape) \n",
        "item_id_atten = Dense(attention_units,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001),kernel_initializer=init_a, bias_initializer=init_b)(item_embs)\n",
        "print(item_id_atten.shape)\n",
        "added = Add()([user_atten,item_id_atten])\n",
        "print(added.shape)\n",
        "added = Activation('relu')(added)\n",
        "user_a = Dense(1,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001),kernel_initializer=init_a, bias_initializer=init_b)(added)\n",
        "print(user_a.shape)\n",
        "user_a = tf.keras.activations.softmax(user_a)\n",
        "\n",
        "## multiply attention weights to learned features from convolution\n",
        "\n",
        "u_feas = Multiply()([user_flat,user_a])\n",
        "print(u_feas.shape)\n",
        "\n",
        "## aggregate features \n",
        "\n",
        "u_feas  = tf.keras.backend.sum(u_feas,axis = 1)\n",
        "print(u_feas.shape)\n",
        "u_feas = Dropout(drop_rate)(u_feas)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 85, 200)\n",
            "(?, 85)\n",
            "(?, 85, 32)\n",
            "(?, 85, 32)\n",
            "(?, 85, 32)\n",
            "(?, 85, 32)\n",
            "(?, 85, 1)\n",
            "(?, 85, 200)\n",
            "(?, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chdo09t-DBKq",
        "colab_type": "code",
        "outputId": "fface67f-48af-488c-ca38-3d0b956a9619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "item_flat = Reshape((item_review_num,conv_filters*len(filter_sizes)))(item_conv_joined)\n",
        "item_flat = Dropout(drop_rate)(item_flat)\n",
        "## concatenate convolution fetures for business\n",
        "\n",
        "#total_users = 200000\n",
        "i_uid = Input(shape=(item_review_num,), dtype='int32')\n",
        "\n",
        "## retreiving the user ids embeddings for a specific business\n",
        "\n",
        "user_id_embedding = Embedding(total_users + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a,embeddings_regularizer=l2(0.001))\n",
        "user_embs = user_id_embedding(i_uid)\n",
        "user_embs = Activation('relu')(user_embs)\n",
        "\n",
        "## Applying business level attention\n",
        "\n",
        "item_atten = Dense(attention_units,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001), kernel_initializer=init_a, bias_initializer=init_b)(item_flat)\n",
        "print(item_atten.shape) \n",
        "user_id_atten = Dense(attention_units,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001), kernel_initializer=init_a, bias_initializer=init_b)(user_embs)\n",
        "print(user_id_atten.shape)\n",
        "item_added = Add()([item_atten,user_id_atten])\n",
        "print(item_added.shape)\n",
        "item_added = Activation('relu')(item_added)\n",
        "item_a = Dense(1,kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001), kernel_initializer=init_a, bias_initializer=init_b)(item_added)\n",
        "print(item_a.shape)\n",
        "item_a = tf.keras.activations.softmax(item_a,axis=1)\n",
        "\n",
        "## multiply attention weights to learned features from convolution\n",
        "\n",
        "i_feas = Multiply()([item_flat,item_a])\n",
        "print(i_feas.shape)\n",
        "i_feas  = tf.keras.backend.sum(i_feas,axis = 1)\n",
        "print(i_feas.shape)\n",
        "i_feas = Dropout(drop_rate)(i_feas)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 169, 32)\n",
            "(?, 169, 32)\n",
            "(?, 169, 32)\n",
            "(?, 169, 1)\n",
            "(?, 169, 200)\n",
            "(?, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9XdtAn8DBKt",
        "colab_type": "code",
        "outputId": "6c1a697c-405c-4824-e8f8-f4a974579909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "## Prediction Layer\n",
        "## Retreive the embedding for the specific user and business\n",
        "## Add this to features learnt for user and business respectively.\n",
        "\n",
        "## Predict using drop or multiply-relu-dropout-dense-sum combination\n",
        "\n",
        "\n",
        "uid = Input(shape=(1), dtype='int32')\n",
        "iid = Input(shape=(1,), dtype='int32')\n",
        "item_id_embedding = Embedding(total_items + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a,embeddings_regularizer=l2(0.001))\n",
        "item_id_emb = item_id_embedding(iid)\n",
        "print(item_id_emb.shape)\n",
        "\n",
        "user_id_embedding = Embedding(total_users + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a,embeddings_regularizer=l2(0.001))\n",
        "user_id_emb = user_id_embedding(uid)\n",
        "print(user_id_emb.shape)\n",
        "\n",
        "u_feas_latent = Dense(embedding_id)(u_feas)\n",
        "print(user_id_atten.shape)\n",
        "u_feas = Add()([u_feas_latent,user_id_emb])\n",
        "\n",
        "i_feas_latent = Dense(embedding_id)(i_feas)\n",
        "i_feas = Add()([i_feas_latent,item_id_emb])\n",
        "print(i_feas.shape,u_feas.shape)\n",
        "u_feas =tf.keras.backend.squeeze(u_feas,axis=1)\n",
        "i_feas =tf.keras.backend.squeeze(i_feas,axis=1)\n",
        "\n",
        "#preds = Dot(axes=-1)([u_feas ,i_feas])\n",
        "#Trial with multiply-drop-dense-add instead of dot\n",
        "\n",
        "mult_feat = Multiply()([u_feas ,i_feas])\n",
        "mult_feat = Activation('relu')(mult_feat)\n",
        "#print(\"feat shape\",mult_feat.shape)\n",
        "mult_feat_drop = Dropout(drop_rate)(mult_feat)\n",
        "\n",
        "mult_score = Dense(embedding_id)(mult_feat_drop)\n",
        "preds = K.sum(mult_score,axis=-1,keepdims=True)\n",
        "\n",
        "print(preds.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1, 32)\n",
            "(?, 1, 32)\n",
            "(?, 169, 32)\n",
            "(?, 1, 32) (?, 1, 32)\n",
            "(?, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z737kt3ebLIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## evaluation metric 1 RMSE\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIouhcHYbMne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def coeff_determination(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTDdUVDVDBKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model loss Mean squared error and optimzer Adam with learning rate 0.001\n",
        "\n",
        "model = Model(inputs=[user_sequence_input,item_sequence_input,u_iid,i_uid,uid,iid], outputs=preds)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='mse',\n",
        "              #loss=,\n",
        "              metrics=[root_mean_squared_error,coeff_determination])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tsKbQJwDs03",
        "colab_type": "code",
        "outputId": "d89f515f-7adc-4cce-b166-736f9856222f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 114, 85)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 114, 169)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 114, 85, 100) 12706400    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 114, 169, 100 12880600    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 85, 114, 100, 0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 169, 114, 100 0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 85, 112, 1, 1 30100       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 85, 111, 1, 1 40100       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 169, 112, 1,  30100       reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 169, 111, 1,  40100       reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D)    (None, 85, 1, 1, 100 0           conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 85, 1, 1, 100 0           conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)  (None, 169, 1, 1, 10 0           conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3D)  (None, 169, 1, 1, 10 0           conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8500)         0           max_pooling3d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8500)         0           max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16900)        0           max_pooling3d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 16900)        0           max_pooling3d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 17000)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 85)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 33800)        0           flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 169)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 85, 200)      0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 85, 32)       126144      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 169, 200)     0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 169, 32)      195680      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 85, 200)      0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 85, 32)       0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 169, 200)     0           reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 169, 32)      0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 85, 32)       6432        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 85, 32)       1056        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 169, 32)      6432        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 169, 32)      1056        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 85, 32)       0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 169, 32)      0           dense_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 85, 32)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 169, 32)      0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 85, 1)        33          activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 169, 1)       33          activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max (TensorFlowOpLa [(None, 85, 1)]      0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max_1 (TensorFlowOp [(None, 1, 1)]       0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub (TensorFlowOpLa [(None, 85, 1)]      0           dense_2[0][0]                    \n",
            "                                                                 tf_op_layer_Max[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_1 (TensorFlowOp [(None, 169, 1)]     0           dense_5[0][0]                    \n",
            "                                                                 tf_op_layer_Max_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp (TensorFlowOpLa [(None, 85, 1)]      0           tf_op_layer_sub[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_1 (TensorFlowOp [(None, 169, 1)]     0           tf_op_layer_sub_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(None, 85, 1)]      0           tf_op_layer_Exp[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_2 (TensorFlowOp [(None, 1, 1)]       0           tf_op_layer_Exp_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv (TensorFlow [(None, 85, 1)]      0           tf_op_layer_Exp[0][0]            \n",
            "                                                                 tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv_1 (TensorFl [(None, 169, 1)]     0           tf_op_layer_Exp_1[0][0]          \n",
            "                                                                 tf_op_layer_Sum_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 85, 200)      0           dropout[0][0]                    \n",
            "                                                                 tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 169, 200)     0           dropout_2[0][0]                  \n",
            "                                                                 tf_op_layer_truediv_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_1 (TensorFlowOp [(None, 200)]        0           multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_3 (TensorFlowOp [(None, 200)]        0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200)          0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200)          0           tf_op_layer_Sum_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 32)           6432        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 32)        195680      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 32)           6432        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 32)        126144      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1, 32)        0           dense_6[0][0]                    \n",
            "                                                                 embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 1, 32)        0           dense_7[0][0]                    \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 32)]         0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_1 (TensorFl [(None, 32)]         0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 32)           0           tf_op_layer_Squeeze[0][0]        \n",
            "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32)           0           multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 32)           1056        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_4 (TensorFlowOp [(None, 1)]          0           dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 26,400,010\n",
            "Trainable params: 813,010\n",
            "Non-trainable params: 25,587,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQPBm-p7DsuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBdsdPIiUhz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D3g-k-0jBle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping train data\n",
        "\n",
        "duid, diid, dreuid, dreiid, y_batch = zip(*train_data)\n",
        "duid, diid, dreuid, dreiid = np.array(list(duid)), np.array(list(diid)), np.array(list(dreuid)), np.array(list(dreiid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efDGCTuYOarc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_batch = np.array(y_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4EMe7mIcdIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping validation data\n",
        "\n",
        "vuid, viid, vreuid, vreiid, y_batch_v = zip(*valid_data)\n",
        "vuid, viid, vreuid, vreiid= np.array(list(vuid)), np.array(list(viid)), np.array(list(vreuid)), np.array(list(vreiid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofGSRi0fs_D9",
        "colab_type": "code",
        "outputId": "9236fb9e-29f2-4f81-c439-de110a536376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "y_batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       ...,\n",
              "       [4.],\n",
              "       [3.],\n",
              "       [5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLKHRZUkcjBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_batch_v = np.array(y_batch_v)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCOsg0Br8eNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generator function defined for training and validation\n",
        "\n",
        "def generator(data, batch_size):\n",
        "  end_batch_ind = len(data)//batch_size\n",
        "  #print(end_batch_ind)\n",
        "  while True:\n",
        "    for ind in range(0,end_batch_ind):\n",
        "      #print(\"ind: \",ind)\n",
        "      train_batch = data[ind*batch_size:(ind+1)*batch_size]\n",
        "      duid, diid, dreuid, dreiid, y_batch = zip(*train_batch)\n",
        "      duid, diid, dreuid, dreiid,y_batch = np.array(list(duid)), np.array(list(diid)), np.array(list(dreuid)), np.array(list(dreiid)),np.array(y_batch)\n",
        "      u_batch = []\n",
        "      i_batch = []\n",
        "      for i in range(len(duid)):\n",
        "        u_batch.append(u_text[duid[i][0]])\n",
        "        i_batch.append(i_text[diid[i][0]])\n",
        "      u_batch = np.array(u_batch)\n",
        "      i_batch = np.array(i_batch)\n",
        "      u_batch = np.swapaxes(u_batch,1,2)\n",
        "      i_batch = np.swapaxes(i_batch,1,2)\n",
        "      yield [u_batch, i_batch, dreuid, dreiid, duid, diid ],y_batch\n",
        "\n",
        "#batch_ind = 0\n",
        "def val_generator(data, batch_size):\n",
        "  end_batch_ind = len(data)//batch_size\n",
        "  #print(\"val, \",end_batch_ind)\n",
        "  while True:\n",
        "    for ind in range(0,end_batch_ind):\n",
        "      #print(\"val ind: \",ind)\n",
        "      train_batch = data[ind*batch_size:(ind+1)*batch_size]\n",
        "      duid, diid, dreuid, dreiid, y_batch = zip(*train_batch)\n",
        "      duid, diid, dreuid, dreiid,y_batch = np.array(list(duid)), np.array(list(diid)), np.array(list(dreuid)), np.array(list(dreiid)),np.array(y_batch)\n",
        "      u_batch = []\n",
        "      i_batch = []\n",
        "      for i in range(len(duid)):\n",
        "        u_batch.append(u_text[duid[i][0]])\n",
        "        i_batch.append(i_text[diid[i][0]])\n",
        "      u_batch = np.array(u_batch)\n",
        "      i_batch = np.array(i_batch)\n",
        "      u_batch = np.swapaxes(u_batch,1,2)\n",
        "      i_batch = np.swapaxes(i_batch,1,2)\n",
        "      yield [u_batch, i_batch, dreuid, dreiid, duid, diid ],y_batch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGf7fQAOb-Et",
        "colab_type": "code",
        "outputId": "6abdcbd3-2237-4f72-9e50-758d15ca4b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "#history = model.fit([u_batch, i_batch, dreuid, dreiid, duid, diid ],y_batch, batch_size=100,epochs = 30, verbose = 1, validation_data = ([u_batch_c, i_batch_c, cvreuid, cvreiid, cvuid, cviid], cy_batch_v),shuffle=True)\n",
        "\n",
        "batch_size=150\n",
        "vbatch_size=150\n",
        "#model.fit_generator(generator(train_data,  batch_size),  steps_per_epoch=len(train_data)//8500,epochs=4,validation_data=generator(valid_data,  vbatch_size),validation_freq=2,validation_steps=len(valid_data)//vbatch_size)\n",
        "model.fit_generator(generator(train_data,  batch_size),  steps_per_epoch=len(train_data)//batch_size,epochs=26,validation_data=val_generator(valid_data,  vbatch_size),validation_freq=1,validation_steps=len(valid_data)//vbatch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 3.6348 - root_mean_squared_error: 1.3960 - coeff_determination: -1.5403Epoch 1/26\n",
            "1587/1587 [==============================] - 1228s 774ms/step - loss: 3.6334 - root_mean_squared_error: 1.3958 - coeff_determination: -1.5392 - val_loss: 1.3289 - val_root_mean_squared_error: 1.1143 - val_coeff_determination: 0.0714\n",
            "Epoch 2/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.3322 - root_mean_squared_error: 1.1211 - coeff_determination: 0.0687Epoch 1/26\n",
            "1587/1587 [==============================] - 1214s 765ms/step - loss: 1.3321 - root_mean_squared_error: 1.1211 - coeff_determination: 0.0688 - val_loss: 1.2680 - val_root_mean_squared_error: 1.0973 - val_coeff_determination: 0.0994\n",
            "Epoch 3/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.2791 - root_mean_squared_error: 1.1046 - coeff_determination: 0.0957Epoch 1/26\n",
            "1587/1587 [==============================] - 1207s 761ms/step - loss: 1.2791 - root_mean_squared_error: 1.1046 - coeff_determination: 0.0957 - val_loss: 1.2172 - val_root_mean_squared_error: 1.0780 - val_coeff_determination: 0.1312\n",
            "Epoch 4/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.2423 - root_mean_squared_error: 1.0910 - coeff_determination: 0.1175Epoch 1/26\n",
            "1587/1587 [==============================] - 1203s 758ms/step - loss: 1.2422 - root_mean_squared_error: 1.0909 - coeff_determination: 0.1176 - val_loss: 1.1862 - val_root_mean_squared_error: 1.0662 - val_coeff_determination: 0.1495\n",
            "Epoch 5/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.2133 - root_mean_squared_error: 1.0800 - coeff_determination: 0.1350Epoch 1/26\n",
            "1587/1587 [==============================] - 1199s 755ms/step - loss: 1.2132 - root_mean_squared_error: 1.0799 - coeff_determination: 0.1351 - val_loss: 1.1687 - val_root_mean_squared_error: 1.0603 - val_coeff_determination: 0.1583\n",
            "Epoch 6/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1991 - root_mean_squared_error: 1.0746 - coeff_determination: 0.1436Epoch 1/26\n",
            "1587/1587 [==============================] - 1197s 754ms/step - loss: 1.1990 - root_mean_squared_error: 1.0746 - coeff_determination: 0.1436 - val_loss: 1.1704 - val_root_mean_squared_error: 1.0612 - val_coeff_determination: 0.1577\n",
            "Epoch 7/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1916 - root_mean_squared_error: 1.0710 - coeff_determination: 0.1492Epoch 1/26\n",
            "1587/1587 [==============================] - 1195s 753ms/step - loss: 1.1916 - root_mean_squared_error: 1.0710 - coeff_determination: 0.1492 - val_loss: 1.1609 - val_root_mean_squared_error: 1.0567 - val_coeff_determination: 0.1645\n",
            "Epoch 8/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1841 - root_mean_squared_error: 1.0675 - coeff_determination: 0.1544Epoch 1/26\n",
            "1587/1587 [==============================] - 1195s 753ms/step - loss: 1.1840 - root_mean_squared_error: 1.0675 - coeff_determination: 0.1545 - val_loss: 1.1526 - val_root_mean_squared_error: 1.0528 - val_coeff_determination: 0.1698\n",
            "Epoch 9/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1759 - root_mean_squared_error: 1.0640 - coeff_determination: 0.1603Epoch 1/26\n",
            "1587/1587 [==============================] - 1195s 753ms/step - loss: 1.1758 - root_mean_squared_error: 1.0639 - coeff_determination: 0.1604 - val_loss: 1.1476 - val_root_mean_squared_error: 1.0504 - val_coeff_determination: 0.1742\n",
            "Epoch 10/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1679 - root_mean_squared_error: 1.0603 - coeff_determination: 0.1658Epoch 1/26\n",
            "1587/1587 [==============================] - 1194s 752ms/step - loss: 1.1679 - root_mean_squared_error: 1.0603 - coeff_determination: 0.1659 - val_loss: 1.1435 - val_root_mean_squared_error: 1.0485 - val_coeff_determination: 0.1769\n",
            "Epoch 11/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1606 - root_mean_squared_error: 1.0570 - coeff_determination: 0.1709Epoch 1/26\n",
            "1587/1587 [==============================] - 1194s 753ms/step - loss: 1.1605 - root_mean_squared_error: 1.0570 - coeff_determination: 0.1710 - val_loss: 1.1407 - val_root_mean_squared_error: 1.0473 - val_coeff_determination: 0.1785\n",
            "Epoch 12/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1626 - root_mean_squared_error: 1.0572 - coeff_determination: 0.1706Epoch 1/26\n",
            "1587/1587 [==============================] - 1194s 752ms/step - loss: 1.1625 - root_mean_squared_error: 1.0572 - coeff_determination: 0.1706 - val_loss: 1.1639 - val_root_mean_squared_error: 1.0575 - val_coeff_determination: 0.1619\n",
            "Epoch 13/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1970 - root_mean_squared_error: 1.0665 - coeff_determination: 0.1481Epoch 1/26\n",
            "1587/1587 [==============================] - 1193s 752ms/step - loss: 1.1969 - root_mean_squared_error: 1.0665 - coeff_determination: 0.1482 - val_loss: 1.1463 - val_root_mean_squared_error: 1.0478 - val_coeff_determination: 0.1778\n",
            "Epoch 14/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1484 - root_mean_squared_error: 1.0499 - coeff_determination: 0.1819Epoch 1/26\n",
            "1587/1587 [==============================] - 1196s 754ms/step - loss: 1.1483 - root_mean_squared_error: 1.0498 - coeff_determination: 0.1820 - val_loss: 1.1379 - val_root_mean_squared_error: 1.0458 - val_coeff_determination: 0.1807\n",
            "Epoch 15/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1517 - root_mean_squared_error: 1.0510 - coeff_determination: 0.1796Epoch 1/26\n",
            "1587/1587 [==============================] - 1194s 752ms/step - loss: 1.1517 - root_mean_squared_error: 1.0510 - coeff_determination: 0.1796 - val_loss: 1.1360 - val_root_mean_squared_error: 1.0445 - val_coeff_determination: 0.1830\n",
            "Epoch 16/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1342 - root_mean_squared_error: 1.0441 - coeff_determination: 0.1910Epoch 1/26\n",
            "1587/1587 [==============================] - 1193s 752ms/step - loss: 1.1341 - root_mean_squared_error: 1.0440 - coeff_determination: 0.1910 - val_loss: 1.1314 - val_root_mean_squared_error: 1.0435 - val_coeff_determination: 0.1842\n",
            "Epoch 17/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1314 - root_mean_squared_error: 1.0432 - coeff_determination: 0.1922Epoch 1/26\n",
            "1587/1587 [==============================] - 1195s 753ms/step - loss: 1.1314 - root_mean_squared_error: 1.0432 - coeff_determination: 0.1922 - val_loss: 1.1391 - val_root_mean_squared_error: 1.0474 - val_coeff_determination: 0.1778\n",
            "Epoch 18/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1265 - root_mean_squared_error: 1.0411 - coeff_determination: 0.1955Epoch 1/26\n",
            "1587/1587 [==============================] - 1195s 753ms/step - loss: 1.1264 - root_mean_squared_error: 1.0410 - coeff_determination: 0.1956 - val_loss: 1.1368 - val_root_mean_squared_error: 1.0458 - val_coeff_determination: 0.1803\n",
            "Epoch 19/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1294 - root_mean_squared_error: 1.0418 - coeff_determination: 0.1944Epoch 1/26\n",
            " 216/1587 [===>..........................] - ETA: 7:24 - loss: 1.1403 - root_mean_squared_error: 1.0474 - coeff_determination: 0.1785"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQskW4dRISqn",
        "colab_type": "code",
        "outputId": "71c8272f-d835-4951-be44-0fca93503ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
        "\n",
        "# print(history.history.keys())\n",
        "plt.plot([1.3958,1.1211,1.1046,1.0909,1.0799,1.0746,1.0710,1.0675,1.0639,1.0603,1.0570,1.0572,1.0665,1.0498,1.0510,1.0440,1.0432,1.0410])\n",
        "plt.plot([1.1143,1.0973,1.0780,1.0662,1.0603,1.0612,1.0567,1.0528,1.0504,1.0485,1.0473,1.0575,1.0478,1.0458,1.0445,1.0435,1.0474,1.0458])  # RAISE ERROR\n",
        "plt.title('model RMSE')\n",
        "plt.grid()\n",
        "plt.ylabel('RMSE')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# # summarize history for loss\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss']) #RAISE ERROR\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ1KqaiHoLbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.unique(y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kaGLWHUolOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n, bins, patches = plt.hist(y_batch)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTVus-5OoqGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n, bins, patches = plt.hist(y_batch_v)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7mV5S9LJ_yy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmizP_A6rqUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}