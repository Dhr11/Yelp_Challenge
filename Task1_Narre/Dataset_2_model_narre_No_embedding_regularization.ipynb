{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Dataset 2 model narre No embedding regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG6OZzVADBKM",
        "colab_type": "code",
        "outputId": "6755d221-54bc-4629-de3f-e7e8f81aa2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#from tensorflow.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.layers import Embedding, Concatenate, Add, Activation,Dot\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten,Reshape, MaxPooling2D,MaxPooling3D\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling1D, Embedding, Dropout, AdditiveAttention, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeVNx2H3ETsD",
        "colab_type": "code",
        "outputId": "a0b60e09-20dc-4961-8041-8d6afa402d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP03F9raD386",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/narre_data/NARRE_para_filtered_short_review.pkl','rb') as f:\n",
        "  para = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/narre_data/yelp_NARRE_train_filtered_short_review.pkl','rb') as f:\n",
        "  train_data = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/narre_data/yelp_NARRE_valid_filtered_short_review.pkl','rb') as f:\n",
        "  valid_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_kDvui8GQK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loading the paramters specific to the data created\n",
        "## parameters like total number of users, business\n",
        "## Max sequence length for user and business reviews\n",
        "## Number of reviews per user and business\n",
        "## text for user and business\n",
        "## Word dictionary for user text and business text\n",
        "\n",
        "total_items = para['item_num']\n",
        "total_users = para['user_num']\n",
        "USER_SEQUENCE_LENGTH = para['review_len_u']\n",
        "ITEM_SEQUENCE_LENGTH = para['review_len_i']\n",
        "user_review_num = para['review_num_u']\n",
        "item_review_num = para['review_num_i']\n",
        "u_text = para['u_text']\n",
        "i_text = para['i_text']\n",
        "user_word_index = para['user_vocab']\n",
        "item_word_index = para['item_vocab']\n",
        "\n",
        "#total_users = 65796\n",
        "#total_items=8000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aACFlZ9qxaf0",
        "colab_type": "code",
        "outputId": "a9520b0e-c4b0-4796-d21c-cbd419fab95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(total_items,total_users,USER_SEQUENCE_LENGTH,ITEM_SEQUENCE_LENGTH,user_review_num,item_review_num)#,u_text,i_text,user_word_index,item_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3940 6113 114 114 85 169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQnFSHGIDBKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Rest of parameters for the model\n",
        "## drop rate of 0.4\n",
        "## Two filter sizes for text cnn, and each has 100 filters\n",
        "## Attention dimension kept as 32, same as latent embedding dimension\n",
        "\n",
        "EMBEDDING_DIM = 100 ##\n",
        "\n",
        "\n",
        "filter_sizes = [3,4]\n",
        "conv_filters = 100\n",
        "drop_rate = 0.4  \n",
        "attention_units = 32\n",
        "embedding_id = 32\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qyPlrNODBKZ",
        "colab_type": "code",
        "outputId": "8de0f83a-05c6-4ffe-c772-f8a6711af92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Loading the glove pre trained embedding and making a matrix named embedding index for it\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/yelp_dataset/Dataset/glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors in Glove 6B 100d.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9wh_9VPDBKf",
        "colab_type": "code",
        "outputId": "205fb9c7-e83b-45a6-d4d5-2cdfdb4bc061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "## here we make and fill the embedding matrix for user text, by retreiving vectors from embedding index cretaed before\n",
        "\n",
        "user_embedding_matrix = np.random.random((len(user_word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in user_word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        user_embedding_matrix[i] = embedding_vector\n",
        "user_embedding_layer = Embedding(len(user_word_index) + 1,\n",
        "                            EMBEDDING_DIM,weights=[user_embedding_matrix],\n",
        "                            input_length=USER_SEQUENCE_LENGTH,trainable=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1UF2IhDBKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## here we make and fill the embedding matrix for business text, by retreiving vectors from embedding index created before\n",
        "\n",
        "item_embedding_matrix = np.random.random((len(item_word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in item_word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        item_embedding_matrix[i] = embedding_vector\n",
        "item_embedding_layer = Embedding(len(item_word_index) + 1,\n",
        "                            EMBEDDING_DIM,weights=[item_embedding_matrix],\n",
        "                            input_length=ITEM_SEQUENCE_LENGTH,trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXs6QL3fDBKk",
        "colab_type": "code",
        "outputId": "18b7a728-4781-44d9-b251-56a42a75957d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "## Passing the user text to embedding and convolution layers\n",
        "\n",
        "user_sequence_input = Input(shape=(USER_SEQUENCE_LENGTH,user_review_num), dtype='int32')\n",
        "print(user_sequence_input.shape)\n",
        "user_embedded_reviews = user_embedding_layer(user_sequence_input)\n",
        "print(user_embedded_reviews.shape)\n",
        "user_embedded_reviews_flat = Reshape((user_review_num,USER_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(user_embedded_reviews)\n",
        "print(user_embedded_reviews_flat.shape)\n",
        "conv_out = []\n",
        "for f_size in filter_sizes:\n",
        "    l_cov1= Conv3D(conv_filters, (1,f_size,EMBEDDING_DIM), activation='relu',padding='valid')(user_embedded_reviews_flat)\n",
        "    print(l_cov1.shape)\n",
        "    l_pool1 = MaxPooling3D(pool_size =(1,USER_SEQUENCE_LENGTH-f_size+1,1),padding='valid')(l_cov1)\n",
        "    print(l_pool1.shape)\n",
        "    l_flat = Flatten()(l_pool1)\n",
        "    print(l_flat.shape)\n",
        "    conv_out.append(l_flat)\n",
        "conv_joined = Concatenate()(conv_out)\n",
        "print(conv_joined.shape)    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 114, 85)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(?, 114, 85, 100)\n",
            "(?, 85, 114, 100, 1)\n",
            "(?, 85, 112, 1, 100)\n",
            "(?, 85, 1, 1, 100)\n",
            "(?, 8500)\n",
            "(?, 85, 111, 1, 100)\n",
            "(?, 85, 1, 1, 100)\n",
            "(?, 8500)\n",
            "(?, 17000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq8c2BfRDBKm",
        "colab_type": "code",
        "outputId": "c887a1ce-4952-4ed9-fbd0-a07dbe7a1058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "## Passing the business text to embedding and convolution layers\n",
        "\n",
        "item_sequence_input = Input(shape=(ITEM_SEQUENCE_LENGTH,item_review_num), dtype='int32')\n",
        "item_embedded_reviews = item_embedding_layer(item_sequence_input)\n",
        "item_embedded_reviews_flat = Reshape((item_review_num,ITEM_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(item_embedded_reviews)\n",
        "print(item_embedded_reviews_flat.shape)\n",
        "item_conv_out = []\n",
        "for f_size in filter_sizes:\n",
        "    l_cov1= Conv3D(conv_filters, (1,f_size,EMBEDDING_DIM), activation='relu',padding='valid')(item_embedded_reviews_flat)\n",
        "    print(l_cov1.shape)\n",
        "    l_pool1 = MaxPooling3D(pool_size =(1,ITEM_SEQUENCE_LENGTH-f_size+1,1),padding='valid')(l_cov1)\n",
        "    print(l_pool1.shape)\n",
        "    l_flat = Flatten()(l_pool1)\n",
        "    print(l_flat.shape)\n",
        "    item_conv_out.append(l_flat)\n",
        "item_conv_joined = Concatenate()(item_conv_out)\n",
        "print(item_conv_joined.shape)    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 169, 114, 100, 1)\n",
            "(?, 169, 112, 1, 100)\n",
            "(?, 169, 1, 1, 100)\n",
            "(?, 16900)\n",
            "(?, 169, 111, 1, 100)\n",
            "(?, 169, 1, 1, 100)\n",
            "(?, 16900)\n",
            "(?, 33800)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aaPm31IDBKo",
        "colab_type": "code",
        "outputId": "1a011b76-2023-4fcb-9924-2df949e66b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "## concatenate convolution fetures for user\n",
        "\n",
        "user_flat = Reshape((user_review_num,conv_filters*len(filter_sizes)))(conv_joined)\n",
        "print(user_flat.shape)\n",
        "user_flat = Dropout(drop_rate)(user_flat)\n",
        "\n",
        "\n",
        "u_iid = Input(shape=(user_review_num), dtype='int32')\n",
        "print(u_iid.shape)\n",
        "init_a = keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=123)\n",
        "init_b = tf.keras.initializers.Constant(0.1)\n",
        "\n",
        "## retreiving the business ids embeddings for a specific user \n",
        "\n",
        "item_id_embedding = Embedding(total_items + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a)\n",
        "item_embs = item_id_embedding(u_iid)\n",
        "item_embs = Activation('relu')(item_embs)\n",
        "print(item_embs.shape)\n",
        "\n",
        "## Applying user level attention\n",
        "\n",
        "user_atten = Dense(attention_units, kernel_initializer=init_a, bias_initializer=init_b)(user_flat)\n",
        "print(user_atten.shape) \n",
        "item_id_atten = Dense(attention_units,kernel_initializer=init_a, bias_initializer=init_b)(item_embs)\n",
        "print(item_id_atten.shape)\n",
        "added = Add()([user_atten,item_id_atten])\n",
        "print(added.shape)\n",
        "added = Activation('relu')(added)\n",
        "user_a = Dense(1,kernel_initializer=init_a, bias_initializer=init_b)(added)\n",
        "print(user_a.shape)\n",
        "user_a = tf.keras.activations.softmax(user_a)\n",
        "\n",
        "## multiply attention weights to learned features from convolution\n",
        "u_feas = Multiply()([user_flat,user_a])\n",
        "print(u_feas.shape)\n",
        "\n",
        "## aggregate features \n",
        "\n",
        "u_feas  = tf.keras.backend.sum(u_feas,axis = 1)\n",
        "print(u_feas.shape)\n",
        "u_feas = Dropout(drop_rate)(u_feas)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 85, 200)\n",
            "(?, 85)\n",
            "(?, 85, 32)\n",
            "(?, 85, 32)\n",
            "(?, 85, 32)\n",
            "(?, 85, 32)\n",
            "(?, 85, 1)\n",
            "(?, 85, 200)\n",
            "(?, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chdo09t-DBKq",
        "colab_type": "code",
        "outputId": "a337a8b9-eb02-436b-b5d4-52fd70733d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "## concatenate convolution fetures for user\n",
        "\n",
        "item_flat = Reshape((item_review_num,conv_filters*len(filter_sizes)))(item_conv_joined)\n",
        "item_flat = Dropout(drop_rate)(item_flat)\n",
        "\n",
        "i_uid = Input(shape=(item_review_num,), dtype='int32')\n",
        "\n",
        "## retreiving the user ids embeddings for a specific business \n",
        "\n",
        "user_id_embedding = Embedding(total_users + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a)\n",
        "user_embs = user_id_embedding(i_uid)\n",
        "user_embs = Activation('relu')(user_embs)\n",
        "\n",
        "## Applying business level attention\n",
        "\n",
        "item_atten = Dense(attention_units, kernel_initializer=init_a, bias_initializer=init_b)(item_flat)\n",
        "print(item_atten.shape) \n",
        "user_id_atten = Dense(attention_units, kernel_initializer=init_a, bias_initializer=init_b)(user_embs)\n",
        "print(user_id_atten.shape)\n",
        "item_added = Add()([item_atten,user_id_atten])\n",
        "print(item_added.shape)\n",
        "item_added = Activation('relu')(item_added)\n",
        "item_a = Dense(1, kernel_initializer=init_a, bias_initializer=init_b)(item_added)\n",
        "print(item_a.shape)\n",
        "item_a = tf.keras.activations.softmax(item_a,axis=1)\n",
        "\n",
        "## multiply attention weights to learned features from convolution\n",
        "\n",
        "i_feas = Multiply()([item_flat,item_a])\n",
        "print(i_feas.shape)\n",
        "\n",
        "## aggregate features \n",
        "i_feas  = tf.keras.backend.sum(i_feas,axis = 1)\n",
        "print(i_feas.shape)\n",
        "i_feas = Dropout(drop_rate)(i_feas)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 169, 32)\n",
            "(?, 169, 32)\n",
            "(?, 169, 32)\n",
            "(?, 169, 1)\n",
            "(?, 169, 200)\n",
            "(?, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9XdtAn8DBKt",
        "colab_type": "code",
        "outputId": "c2e7658b-73a3-477f-91ad-8c58749f4f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "## Prediction Layer\n",
        "## Retreive the embedding for the specific user and business\n",
        "## Add this to features learnt for user and business respectively.\n",
        "\n",
        "## Predict using drop or multiply-relu-dropout-dense-sum combination\n",
        "\n",
        "uid = Input(shape=(1), dtype='int32')\n",
        "iid = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "item_id_embedding = Embedding(total_items + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a)\n",
        "item_id_emb = item_id_embedding(iid)\n",
        "print(item_id_emb.shape)\n",
        "\n",
        "user_id_embedding = Embedding(total_users + 2,\n",
        "                            embedding_id,\n",
        "                            input_length=1,trainable=True,embeddings_initializer=init_a)\n",
        "user_id_emb = user_id_embedding(uid)\n",
        "print(user_id_emb.shape)\n",
        "\n",
        "u_feas_latent = Dense(embedding_id)(u_feas)\n",
        "print(user_id_atten.shape)\n",
        "u_feas = Add()([u_feas_latent,user_id_emb])\n",
        "\n",
        "i_feas_latent = Dense(embedding_id)(i_feas)\n",
        "i_feas = Add()([i_feas_latent,item_id_emb])\n",
        "print(i_feas.shape,u_feas.shape)\n",
        "u_feas =tf.keras.backend.squeeze(u_feas,axis=1)\n",
        "i_feas =tf.keras.backend.squeeze(i_feas,axis=1)\n",
        "\n",
        "#preds = Dot(axes=-1)([u_feas ,i_feas])\n",
        "#Trial with multiply-drop-dense-add instead of dot\n",
        "\n",
        "mult_feat = Multiply()([u_feas ,i_feas])\n",
        "mult_feat = Activation('relu')(mult_feat)\n",
        "#print(\"feat shape\",mult_feat.shape)\n",
        "mult_feat_drop = Dropout(drop_rate)(mult_feat)\n",
        "\n",
        "mult_score = Dense(embedding_id)(mult_feat_drop)\n",
        "preds = K.sum(mult_score,axis=-1,keepdims=True)\n",
        "\n",
        "print(preds.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1, 32)\n",
            "(?, 1, 32)\n",
            "(?, 169, 32)\n",
            "(?, 1, 32) (?, 1, 32)\n",
            "(?, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z737kt3ebLIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## evaluation metric 1 RMSE\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIouhcHYbMne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## EVALUATION METRIC 2 R Squared\n",
        "def coeff_determination(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTDdUVDVDBKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model loss Mean squared error and optimzer Adam with learning rate 0.001\n",
        "\n",
        "model = Model(inputs=[user_sequence_input,item_sequence_input,u_iid,i_uid,uid,iid], outputs=preds)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='mse',\n",
        "              #loss=,\n",
        "              metrics=[root_mean_squared_error,coeff_determination])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tsKbQJwDs03",
        "colab_type": "code",
        "outputId": "afe7d7dc-0220-411f-b8c9-df8223bbc7df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 114, 85)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 114, 169)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 114, 85, 100) 12706400    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 114, 169, 100 12880600    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 85, 114, 100, 0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 169, 114, 100 0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 85, 112, 1, 1 30100       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 85, 111, 1, 1 40100       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 169, 112, 1,  30100       reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 169, 111, 1,  40100       reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D)    (None, 85, 1, 1, 100 0           conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 85, 1, 1, 100 0           conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)  (None, 169, 1, 1, 10 0           conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3D)  (None, 169, 1, 1, 10 0           conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8500)         0           max_pooling3d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8500)         0           max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16900)        0           max_pooling3d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 16900)        0           max_pooling3d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 17000)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 85)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 33800)        0           flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 169)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 85, 200)      0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 85, 32)       126144      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 169, 200)     0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 169, 32)      195680      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 85, 200)      0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 85, 32)       0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 169, 200)     0           reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 169, 32)      0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 85, 32)       6432        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 85, 32)       1056        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 169, 32)      6432        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 169, 32)      1056        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 85, 32)       0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 169, 32)      0           dense_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 85, 32)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 169, 32)      0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 85, 1)        33          activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 169, 1)       33          activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max (TensorFlowOpLa [(None, 85, 1)]      0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max_1 (TensorFlowOp [(None, 1, 1)]       0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub (TensorFlowOpLa [(None, 85, 1)]      0           dense_2[0][0]                    \n",
            "                                                                 tf_op_layer_Max[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_1 (TensorFlowOp [(None, 169, 1)]     0           dense_5[0][0]                    \n",
            "                                                                 tf_op_layer_Max_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp (TensorFlowOpLa [(None, 85, 1)]      0           tf_op_layer_sub[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_1 (TensorFlowOp [(None, 169, 1)]     0           tf_op_layer_sub_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(None, 85, 1)]      0           tf_op_layer_Exp[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_2 (TensorFlowOp [(None, 1, 1)]       0           tf_op_layer_Exp_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv (TensorFlow [(None, 85, 1)]      0           tf_op_layer_Exp[0][0]            \n",
            "                                                                 tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv_1 (TensorFl [(None, 169, 1)]     0           tf_op_layer_Exp_1[0][0]          \n",
            "                                                                 tf_op_layer_Sum_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 85, 200)      0           dropout[0][0]                    \n",
            "                                                                 tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 169, 200)     0           dropout_2[0][0]                  \n",
            "                                                                 tf_op_layer_truediv_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_1 (TensorFlowOp [(None, 200)]        0           multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_3 (TensorFlowOp [(None, 200)]        0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200)          0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 200)          0           tf_op_layer_Sum_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 32)           6432        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 32)        195680      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 32)           6432        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 32)        126144      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1, 32)        0           dense_6[0][0]                    \n",
            "                                                                 embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 1, 32)        0           dense_7[0][0]                    \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 32)]         0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_1 (TensorFl [(None, 32)]         0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 32)           0           tf_op_layer_Squeeze[0][0]        \n",
            "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32)           0           multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 32)           1056        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_4 (TensorFlowOp [(None, 1)]          0           dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 26,400,010\n",
            "Trainable params: 813,010\n",
            "Non-trainable params: 25,587,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQPBm-p7DsuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBdsdPIiUhz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D3g-k-0jBle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping train data\n",
        "\n",
        "duid, diid, dreuid, dreiid, y_batch = zip(*train_data)\n",
        "duid, diid, dreuid, dreiid = np.array(list(duid)), np.array(list(diid)), np.array(list(dreuid)), np.array(list(dreiid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efDGCTuYOarc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_batch = np.array(y_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4EMe7mIcdIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping validation data\n",
        "\n",
        "vuid, viid, vreuid, vreiid, y_batch_v = zip(*valid_data)\n",
        "vuid, viid, vreuid, vreiid= np.array(list(vuid)), np.array(list(viid)), np.array(list(vreuid)), np.array(list(vreiid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofGSRi0fs_D9",
        "colab_type": "code",
        "outputId": "eb593cd7-8ef9-4754-d758-40b06e6db0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "y_batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       ...,\n",
              "       [4.],\n",
              "       [3.],\n",
              "       [5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLKHRZUkcjBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_batch_v = np.array(y_batch_v)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCOsg0Br8eNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generator function defined for training and validation\n",
        "\n",
        "def generator(data, batch_size):\n",
        "  end_batch_ind = len(data)//batch_size\n",
        "  #print(end_batch_ind)\n",
        "  while True:\n",
        "    for ind in range(0,end_batch_ind):\n",
        "      #print(\"ind: \",ind)\n",
        "      train_batch = data[ind*batch_size:(ind+1)*batch_size]\n",
        "      duid, diid, dreuid, dreiid, y_batch = zip(*train_batch)\n",
        "      duid, diid, dreuid, dreiid,y_batch = np.array(list(duid)), np.array(list(diid)), np.array(list(dreuid)), np.array(list(dreiid)),np.array(y_batch)\n",
        "      u_batch = []\n",
        "      i_batch = []\n",
        "      for i in range(len(duid)):\n",
        "        u_batch.append(u_text[duid[i][0]])\n",
        "        i_batch.append(i_text[diid[i][0]])\n",
        "      u_batch = np.array(u_batch)\n",
        "      i_batch = np.array(i_batch)\n",
        "      u_batch = np.swapaxes(u_batch,1,2)\n",
        "      i_batch = np.swapaxes(i_batch,1,2)\n",
        "      yield [u_batch, i_batch, dreuid, dreiid, duid, diid ],y_batch\n",
        "\n",
        "def val_generator(data, batch_size):\n",
        "  end_batch_ind = len(data)//batch_size\n",
        "  #print(\"val, \",end_batch_ind)\n",
        "  while True:\n",
        "    for ind in range(0,end_batch_ind):\n",
        "      #print(\"val ind: \",ind)\n",
        "      train_batch = data[ind*batch_size:(ind+1)*batch_size]\n",
        "      duid, diid, dreuid, dreiid, y_batch = zip(*train_batch)\n",
        "      duid, diid, dreuid, dreiid,y_batch = np.array(list(duid)), np.array(list(diid)), np.array(list(dreuid)), np.array(list(dreiid)),np.array(y_batch)\n",
        "      u_batch = []\n",
        "      i_batch = []\n",
        "      for i in range(len(duid)):\n",
        "        u_batch.append(u_text[duid[i][0]])\n",
        "        i_batch.append(i_text[diid[i][0]])\n",
        "      u_batch = np.array(u_batch)\n",
        "      i_batch = np.array(i_batch)\n",
        "      u_batch = np.swapaxes(u_batch,1,2)\n",
        "      i_batch = np.swapaxes(i_batch,1,2)\n",
        "      yield [u_batch, i_batch, dreuid, dreiid, duid, diid ],y_batch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGf7fQAOb-Et",
        "colab_type": "code",
        "outputId": "6afb457e-7ffd-4be0-9ce5-a37227e61b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## model fit generator\n",
        "\n",
        "batch_size=150\n",
        "vbatch_size=150\n",
        "#model.fit_generator(generator(train_data,  batch_size),  steps_per_epoch=len(train_data)//8500,epochs=4,validation_data=generator(valid_data,  vbatch_size),validation_freq=2,validation_steps=len(valid_data)//vbatch_size)\n",
        "model.fit_generator(generator(train_data,  batch_size),  steps_per_epoch=len(train_data)//batch_size,epochs=26,validation_data=val_generator(valid_data,  vbatch_size),validation_freq=1,validation_steps=len(valid_data)//vbatch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 3.6392 - root_mean_squared_error: 1.3764 - coeff_determination: -1.6445Epoch 1/26\n",
            "1587/1587 [==============================] - 1216s 766ms/step - loss: 3.6378 - root_mean_squared_error: 1.3763 - coeff_determination: -1.6434 - val_loss: 1.3120 - val_root_mean_squared_error: 1.1436 - val_coeff_determination: 0.0226\n",
            "Epoch 2/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.2897 - root_mean_squared_error: 1.1338 - coeff_determination: 0.0477Epoch 1/26\n",
            "1587/1587 [==============================] - 1202s 757ms/step - loss: 1.2897 - root_mean_squared_error: 1.1337 - coeff_determination: 0.0477 - val_loss: 1.2178 - val_root_mean_squared_error: 1.1018 - val_coeff_determination: 0.0920\n",
            "Epoch 3/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.2065 - root_mean_squared_error: 1.0964 - coeff_determination: 0.1091Epoch 1/26\n",
            "1587/1587 [==============================] - 1197s 754ms/step - loss: 1.2065 - root_mean_squared_error: 1.0964 - coeff_determination: 0.1091 - val_loss: 1.1448 - val_root_mean_squared_error: 1.0682 - val_coeff_determination: 0.1461\n",
            "Epoch 4/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1317 - root_mean_squared_error: 1.0618 - coeff_determination: 0.1641Epoch 1/26\n",
            "1587/1587 [==============================] - 1194s 752ms/step - loss: 1.1316 - root_mean_squared_error: 1.0617 - coeff_determination: 0.1642 - val_loss: 1.1146 - val_root_mean_squared_error: 1.0540 - val_coeff_determination: 0.1683\n",
            "Epoch 5/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.0860 - root_mean_squared_error: 1.0399 - coeff_determination: 0.1976Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 750ms/step - loss: 1.0859 - root_mean_squared_error: 1.0398 - coeff_determination: 0.1977 - val_loss: 1.1053 - val_root_mean_squared_error: 1.0494 - val_coeff_determination: 0.1752\n",
            "Epoch 6/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.6858 - root_mean_squared_error: 1.1670 - coeff_determination: -0.2660Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 751ms/step - loss: 1.6855 - root_mean_squared_error: 1.1670 - coeff_determination: -0.2657 - val_loss: 1.2635 - val_root_mean_squared_error: 1.1119 - val_coeff_determination: 0.0557\n",
            "Epoch 7/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.3516 - root_mean_squared_error: 1.1082 - coeff_determination: 0.0023Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 751ms/step - loss: 1.3515 - root_mean_squared_error: 1.1082 - coeff_determination: 0.0024 - val_loss: 1.1487 - val_root_mean_squared_error: 1.0701 - val_coeff_determination: 0.1425\n",
            "Epoch 8/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.1065 - root_mean_squared_error: 1.0487 - coeff_determination: 0.1823Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 751ms/step - loss: 1.1064 - root_mean_squared_error: 1.0486 - coeff_determination: 0.1824 - val_loss: 1.1010 - val_root_mean_squared_error: 1.0475 - val_coeff_determination: 0.1781\n",
            "Epoch 9/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.0643 - root_mean_squared_error: 1.0274 - coeff_determination: 0.2131Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 751ms/step - loss: 1.0642 - root_mean_squared_error: 1.0274 - coeff_determination: 0.2131 - val_loss: 1.0928 - val_root_mean_squared_error: 1.0435 - val_coeff_determination: 0.1844\n",
            "Epoch 10/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 1.0250 - root_mean_squared_error: 1.0101 - coeff_determination: 0.2422Epoch 1/26\n",
            "1587/1587 [==============================] - 1192s 751ms/step - loss: 1.0249 - root_mean_squared_error: 1.0101 - coeff_determination: 0.2423 - val_loss: 1.0960 - val_root_mean_squared_error: 1.0451 - val_coeff_determination: 0.1818\n",
            "Epoch 11/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.9943 - root_mean_squared_error: 0.9950 - coeff_determination: 0.2647Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 751ms/step - loss: 0.9942 - root_mean_squared_error: 0.9950 - coeff_determination: 0.2648 - val_loss: 1.1003 - val_root_mean_squared_error: 1.0471 - val_coeff_determination: 0.1785\n",
            "Epoch 12/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.9831 - root_mean_squared_error: 0.9881 - coeff_determination: 0.2729Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 750ms/step - loss: 0.9830 - root_mean_squared_error: 0.9881 - coeff_determination: 0.2730 - val_loss: 1.1362 - val_root_mean_squared_error: 1.0642 - val_coeff_determination: 0.1505\n",
            "Epoch 13/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.9554 - root_mean_squared_error: 0.9734 - coeff_determination: 0.2941Epoch 1/26\n",
            "1587/1587 [==============================] - 1190s 750ms/step - loss: 0.9553 - root_mean_squared_error: 0.9734 - coeff_determination: 0.2942 - val_loss: 1.1139 - val_root_mean_squared_error: 1.0536 - val_coeff_determination: 0.1681\n",
            "Epoch 14/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.9130 - root_mean_squared_error: 0.9533 - coeff_determination: 0.3246Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 750ms/step - loss: 0.9130 - root_mean_squared_error: 0.9534 - coeff_determination: 0.3246 - val_loss: 1.1323 - val_root_mean_squared_error: 1.0623 - val_coeff_determination: 0.1538\n",
            "Epoch 15/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.8843 - root_mean_squared_error: 0.9381 - coeff_determination: 0.3459Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 751ms/step - loss: 0.8843 - root_mean_squared_error: 0.9381 - coeff_determination: 0.3459 - val_loss: 1.1401 - val_root_mean_squared_error: 1.0659 - val_coeff_determination: 0.1481\n",
            "Epoch 16/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.8554 - root_mean_squared_error: 0.9227 - coeff_determination: 0.3668Epoch 1/26\n",
            "1587/1587 [==============================] - 1192s 751ms/step - loss: 0.8554 - root_mean_squared_error: 0.9227 - coeff_determination: 0.3669 - val_loss: 1.1475 - val_root_mean_squared_error: 1.0693 - val_coeff_determination: 0.1427\n",
            "Epoch 17/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.8280 - root_mean_squared_error: 0.9079 - coeff_determination: 0.3868Epoch 1/26\n",
            "1587/1587 [==============================] - 1191s 750ms/step - loss: 0.8280 - root_mean_squared_error: 0.9079 - coeff_determination: 0.3869 - val_loss: 1.1556 - val_root_mean_squared_error: 1.0730 - val_coeff_determination: 0.1369\n",
            "Epoch 18/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.8033 - root_mean_squared_error: 0.8942 - coeff_determination: 0.4055Epoch 1/26\n",
            "1587/1587 [==============================] - 1190s 750ms/step - loss: 0.8032 - root_mean_squared_error: 0.8941 - coeff_determination: 0.4055 - val_loss: 1.1663 - val_root_mean_squared_error: 1.0780 - val_coeff_determination: 0.1285\n",
            "Epoch 19/26\n",
            "1586/1587 [============================>.] - ETA: 0s - loss: 0.7804 - root_mean_squared_error: 0.8814 - coeff_determination: 0.4220Epoch 1/26\n",
            "1587/1587 [==============================] - 1190s 750ms/step - loss: 0.7805 - root_mean_squared_error: 0.8814 - coeff_determination: 0.4220 - val_loss: 1.1782 - val_root_mean_squared_error: 1.0835 - val_coeff_determination: 0.1196\n",
            "Epoch 20/26\n",
            "  87/1587 [>.............................] - ETA: 16:44 - loss: 0.7717 - root_mean_squared_error: 0.8762 - coeff_determination: 0.4340"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kaGLWHUolOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n, bins, patches = plt.hist(y_batch)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTVus-5OoqGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n, bins, patches = plt.hist(y_batch_v)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7mV5S9LJ_yy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmizP_A6rqUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}